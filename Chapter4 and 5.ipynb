{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、Pandas 统计分析基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.读取查看P2P网贷数据主表基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "master = pd.read_csv(\"Training_Master.csv\",encoding='gbk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）使用ndim、shape、memory_usage属性分别查看维度、大小、占用内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data frame 's dimensions:\",master.ndim)\n",
    "print(\"Data frame 's shape:\",master.shape)\n",
    "print(\"Data frame 's memory_usage:\",master.memory_usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）使用describe方法进行描述性统计，剔除值相同或全空的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropNullStd(data):\n",
    "    beforelen = data.shape[1]\n",
    "    colisNull = data.describe().loc['count']==0 #计数为0，即空列\n",
    "    for i in range(len(colisNull)):\n",
    "        if colisNull[i]:\n",
    "            data.drop((colisNull).index[i],axis=1,inplace=True)\n",
    "    stdisZero = data.describe().loc['std'] == 0 #标准差同，值相同\n",
    "    for i in range(len(stdisZero)):\n",
    "        if stdisZero[i]:\n",
    "            data.drop(stdisZero.index[i],axis=1,inplace=True)\n",
    "    afterlen = data.shape[1]\n",
    "    print('Deleted:',beforelen-afterlen)\n",
    "    print('Shape after change:',data.shape)\n",
    "dropNullStd(master)\n",
    "master.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "master = pd.read_csv(\"Training_Master.csv\",encoding='gbk')\n",
    "\n",
    "def dropNullStd(data):\n",
    "    beforelen = data.shape[1]\n",
    "    colisNull = data.describe().loc['count']==0 #计数为0，即空列\n",
    "    for i in range(len(colisNull)):\n",
    "        if colisNull[i]:\n",
    "            data.drop((colisNull).index[i],axis=1,inplace=True)\n",
    "    stdisZero = data.describe().loc['std'] == 0 #标准差同，值相同\n",
    "    for i in range(len(stdisZero)):\n",
    "        if stdisZero[i]:\n",
    "            data.drop(stdisZero.index[i],axis=1,inplace=True)\n",
    "    afterlen = data.shape[1]\n",
    "    print('Deleted:',beforelen-afterlen)\n",
    "    print('Shape after change:',data.shape)\n",
    "\n",
    "print(\"Data frame 's dimensions:\",master.ndim)\n",
    "print(\"Data frame 's shape:\",master.shape)\n",
    "print(\"Data frame 's memory_usage:\",master.memory_usage)\n",
    "dropNullStd(master)\n",
    "master.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.提取用户信息更新表与登录信息表的时间信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）使用to_datetime函数转换用户信息更新表、登录信息表的时间字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "update = pd.read_csv(\"Training_Userupdate.csv\")\n",
    "login = pd.read_csv(\"Training_LogInfo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）使用year、month、week 等方法提取两个表中的时间信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Method 1:use DateIndex,but seems the result can not be calculalted.\n",
    "\n",
    "dateIndex_update_listing = pd.DatetimeIndex(update['ListingInfo1'])\n",
    "dateIndex_update_user = pd.DatetimeIndex(update['UserupdateInfo2'])\n",
    "\n",
    "\n",
    "dateIndex_login_listing = pd.DatetimeIndex(login['ListingInfo1'])\n",
    "dateIndex_login_user = pd.DatetimeIndex(login['LogInfo3'])\n",
    "\n",
    "year_update_listing = dateIndex_update_listing.year\n",
    "month_update_listing = dateIndex_update_listing.month\n",
    "day_update_listing = dateIndex_update_listing.day\n",
    "week_update_listing = dateIndex_update_listing.week\n",
    "\n",
    "year_update_user = dateIndex_update_user.year\n",
    "month_update_user = dateIndex_update_user.month\n",
    "day_update_user = dateIndex_update_user.day\n",
    "week_update_user = dateIndex_update_user.week\n",
    "\n",
    "year_login_listing = dateIndex_login_listing.year\n",
    "month_login_listing = dateIndex_login_listing.month\n",
    "day_login_listing = dateIndex_login_listing.day\n",
    "week_login_listing = dateIndex_login_listing.week\n",
    "\n",
    "year_login_user = dateIndex_login_user.year\n",
    "month_login_user = dateIndex_login_user.month\n",
    "day_login_user = dateIndex_login_user.day\n",
    "week_login_user = dateIndex_login_user.week\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print(login.dtypes)\n",
    "# Method 2:transform data type of the column\n",
    "update['ListingInfo1'] = pd.to_datetime(update['ListingInfo1'])\n",
    "update['UserupdateInfo2'] = pd.to_datetime(update['UserupdateInfo2'])\n",
    "\n",
    "login['Listinginfo1'] = pd.to_datetime(login['Listinginfo1'])\n",
    "login['LogInfo3'] = pd.to_datetime(login['LogInfo3'])\n",
    "\n",
    "\n",
    "year_update_listing = [i.year for i in update['ListingInfo1']]\n",
    "month_update_listing = [i.month for i in update['ListingInfo1']]\n",
    "day_update_listing = [i.day for i in update['ListingInfo1']]\n",
    "week_update_listing = [i.week for i in update['ListingInfo1']]\n",
    "\n",
    "year_update_user = [j.year for j in update['UserupdateInfo2']]\n",
    "month_update_user = [j.month for j in update['UserupdateInfo2']]\n",
    "day_update_user = [i.day for i in update['UserupdateInfo2']]\n",
    "week_update_user = [j.week for j in update['UserupdateInfo2']]\n",
    "\n",
    "year_login_listing = [k.year for k in login['Listinginfo1']]\n",
    "month_login_listing = [k.month for k in login['Listinginfo1']]\n",
    "day_login_listing = [k.day for k in login['Listinginfo1']]\n",
    "week_login_listing = [k.week for k in login['Listinginfo1']]\n",
    "\n",
    "year_login_user = [l.year for l in login['LogInfo3']]\n",
    "month_login_user = [l.month for l in login['LogInfo3']]\n",
    "day_login_user = [l.day for l in login['LogInfo3']]\n",
    "week_login_user = [l.week for l in login['LogInfo3']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （3）计算两个表中两时间的差，分别以日、小时、分钟计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "update_delta = update['ListingInfo1'] -update['UserupdateInfo2']\n",
    "login_delta = login['Listinginfo1']-login['LogInfo3']\n",
    "\n",
    "\n",
    "print('day difference in update table:',[i.days for i in update_delta])\n",
    "print('hour difference in update table:',[i.days*24 for i in update_delta])\n",
    "print('minute difference in update table:',[i.days*24*60 for i in update_delta])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.使用分组聚合方法进一步分析用户信息更新表和登录信息表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "update = pd.read_csv(\"Training_Userupdate.csv\")\n",
    "login = pd.read_csv(\"Training_LogInfo.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）使用groupby方法对用户信息更新表、登录信息表分组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_group = update.groupby(by='Idx')\n",
    "login_group = login.groupby(by='Idx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）使用agg方法求取分组后的最早和最晚更新及登录时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_group_time = update_group[['ListingInfo1','UserupdateInfo2']].agg([np.min,np.max])\n",
    "login_group_time = login_group[['Listinginfo1','LogInfo3']].agg([np.min,np.max])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （3）使用size方法求取分组后的数据的信息更新次数，登录次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_times = update_group.size()\n",
    "login_times = login_group.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "update = pd.read_csv(\"Training_Userupdate.csv\")\n",
    "login = pd.read_csv(\"Training_LogInfo.csv\")\n",
    "\n",
    "# Group by index\n",
    "update_group = update.groupby(by='Idx')\n",
    "login_group = login.groupby(by='Idx')\n",
    "\n",
    "# Get the earliest and the latest time\n",
    "update_group_time = update_group[['ListingInfo1','UserupdateInfo2']].agg([np.min,np.max])\n",
    "login_group_time = login_group[['Listinginfo1','LogInfo3']].agg([np.min,np.max])\n",
    "\n",
    "# Get the times of update and login\n",
    "update_times = update_group.size()\n",
    "login_times = login_group.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.对用户信息更新表、登录信息表进行长宽表转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Idx', 'ListingInfo1', 'UserupdateInfo1', 'UserupdateInfo2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "update = pd.read_csv(\"Training_Userupdate.csv\")\n",
    "login = pd.read_csv(\"Training_LogInfo.csv\")\n",
    "#update[['ListingInfo1','UserupdateInfo2']]\n",
    "print (update.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）使用pivot_table函数进行长宽表转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "update = pd.read_csv(\"Training_Userupdate.csv\")\n",
    "login = pd.read_csv(\"Training_LogInfo.csv\")\n",
    "update_pivot = pd.pivot_table(update[['Idx','ListingInfo1','UserupdateInfo2']],index='Idx',aggfunc=np.min,margins=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）使用crosstab方法进行长宽表转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ListingInfo1 UserupdateInfo2\n",
      "Idx                               \n",
      "3        2013-11-5       2013-8-30\n",
      "5        2013-11-7      2013-10-24\n",
      "8        2013-11-6      2013-10-25\n",
      "12       2013-11-1       2012-12-8\n",
      "16       2013-11-5      2013-10-27\n",
      "17       2013-11-5      2013-10-27\n",
      "18       2013-11-1      2013-10-27\n",
      "20       2013-11-1      2013-10-27\n",
      "21       2013-11-1      2013-10-28\n",
      "23       2013-11-1       2013-8-11\n",
      "29       2013-11-1      2013-10-28\n",
      "31       2013-11-5      2013-10-28\n",
      "33       2013-11-1      2013-10-28\n",
      "35       2013-11-5      2013-10-21\n",
      "36       2013-11-1      2013-10-28\n",
      "37       2013-11-1      2013-10-28\n",
      "41       2013-11-7      2013-10-29\n",
      "43       2013-11-4      2013-10-29\n",
      "48       2013-11-9      2013-10-31\n",
      "51       2013-11-5      2013-10-29\n",
      "57       2013-11-1      2013-10-29\n",
      "62       2013-11-5      2013-10-30\n",
      "67       2013-11-7      2013-10-29\n",
      "68       2013-11-1       2013-8-26\n",
      "71       2013-11-4      2013-10-29\n",
      "73       2013-11-1      2013-10-29\n",
      "75       2013-11-5      2013-10-29\n",
      "80       2013-11-1      2013-10-28\n",
      "81       2013-11-4      2013-10-29\n",
      "82       2013-11-1      2013-10-29\n",
      "...            ...             ...\n",
      "91613   2014-10-29      2014-10-26\n",
      "91617    2014-11-3      2014-10-26\n",
      "91618    2014-11-4      2014-10-25\n",
      "91620    2014-11-2      2014-10-26\n",
      "91626   2014-10-30      2014-10-26\n",
      "91628    2014-11-2      2014-10-26\n",
      "91630   2014-10-31      2014-10-26\n",
      "91635   2014-10-30      2014-10-26\n",
      "91642    2014-11-2      2014-10-26\n",
      "91643    2014-11-3      2014-10-26\n",
      "91646   2014-10-29      2014-10-25\n",
      "91647    2014-11-4      2012-10-11\n",
      "91660    2014-11-3      2014-10-26\n",
      "91666    2014-11-5      2014-10-26\n",
      "91668   2014-10-30      2014-10-26\n",
      "91670   2014-10-28      2014-10-19\n",
      "91672    2014-11-3       2013-3-27\n",
      "91674    2014-11-3      2014-10-26\n",
      "91676    2014-11-2      2014-10-26\n",
      "91677    2014-11-4      2014-10-26\n",
      "91680   2014-10-28      2014-10-26\n",
      "91681   2014-10-31      2014-10-26\n",
      "91686   2014-10-28      2014-10-26\n",
      "91688   2014-10-30      2014-10-26\n",
      "91689   2014-10-29      2014-10-26\n",
      "91693    2014-11-6      2014-10-26\n",
      "91695   2014-10-30      2014-10-26\n",
      "91702    2014-11-2      2014-10-26\n",
      "91703    2014-11-3      2014-10-26\n",
      "All      2013-11-1       2012-10-1\n",
      "\n",
      "[29996 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(update_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
